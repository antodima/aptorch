{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a958359f",
   "metadata": {},
   "source": [
    "# Diffusion Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb50881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from aptorch.data import (\n",
    "    DivinaCommediaDataset,\n",
    "    divina_commedia,\n",
    "    divina_commedia_tokenizer,\n",
    ")\n",
    "from aptorch.dlm import DLM, pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = divina_commedia()\n",
    "tokenizer = divina_commedia_tokenizer(train_dataset)\n",
    "train_set = DivinaCommediaDataset(dataset=train_dataset)\n",
    "test_set = DivinaCommediaDataset(dataset=test_dataset)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    prompts = [tup[0] for tup in batch]\n",
    "    responses = [tup[1] for tup in batch]\n",
    "    prompts_enc = torch.tensor(\n",
    "        [enc.ids for enc in tokenizer.encode_batch(prompts)])\n",
    "    responses_enc = torch.tensor(\n",
    "        [enc.ids for enc in tokenizer.encode_batch(responses)])\n",
    "    return prompts_enc, responses_enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "n_epochs = 20\n",
    "batch_size = 8\n",
    "emb_dim = 16\n",
    "ff_dim = 32\n",
    "mask_ratio = random.uniform(0.01, 0.99)\n",
    "pad_token_id = (tokenizer.encode(\"[PAD]\").ids)[0]\n",
    "mask_token_id = (tokenizer.encode(\"[MASK]\").ids)[0]\n",
    "num_tokens = tokenizer.get_vocab_size()\n",
    "\n",
    "print(\">> Pretraining step:\")\n",
    "print(f\"mask_ratio: {mask_ratio}\")\n",
    "print(f\"pad_token_id: {pad_token_id}\")\n",
    "print(f\"mask_token_id: {mask_token_id}\")\n",
    "print(f\"num_tokens: {num_tokens}\")\n",
    "\n",
    "model: DLM = pretraining(\n",
    "    training_set=train_set,\n",
    "    collate_fn=collate_fn,\n",
    "    lr=lr,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    emb_dim=emb_dim,\n",
    "    ff_dim=ff_dim,\n",
    "    mask_ratio=mask_ratio,\n",
    "    pad_idx=pad_token_id,\n",
    "    mask_idx=mask_token_id,\n",
    "    num_tokens=num_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89541b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model.eval()\n",
    "num_sampling_steps = 10\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, collate_fn=collate_fn, batch_size=1, shuffle=False)\n",
    "x, y = next(iter(train_loader))\n",
    "x_masked = x.clone()\n",
    "x_masked[:,-3:] = mask_token_id\n",
    "\n",
    "print(tokenizer.decode_batch(x.tolist()))\n",
    "print(x.tolist())\n",
    "print(x_masked.tolist())\n",
    "\n",
    "max_seq_len = x_masked.shape[1]\n",
    "prompt_len = x_masked.shape[1] - 3\n",
    "initial_response_len = max_seq_len - prompt_len\n",
    "masked_response_part = torch.full(\n",
    "    (1, initial_response_len), mask_token_id, dtype=torch.long)\n",
    "\n",
    "current_sequence = x_masked #torch.cat((x, masked_response_part), dim=-1)\n",
    "response_indices_slice = slice(prompt_len, max_seq_len)\n",
    "timesteps = torch.linspace(1.0, 0.0, num_sampling_steps + 1)\n",
    "# print(\"timesteps\", timesteps)\n",
    "for step_idx in range(num_sampling_steps):\n",
    "    current_t_val = 1.0 - (step_idx / num_sampling_steps)\n",
    "    next_t_val = 1.0 - ((step_idx + 1) / num_sampling_steps)\n",
    "    logits = model(current_sequence)\n",
    "    predicted_tokens_all = torch.argmax(logits, dim=-1)\n",
    "    masked_in_response = (\n",
    "        current_sequence[:, response_indices_slice] == mask_token_id)\n",
    "    r0_candidate = current_sequence.clone()\n",
    "    r0_candidate[:, response_indices_slice] = torch.where(\n",
    "        masked_in_response,\n",
    "        predicted_tokens_all[:, response_indices_slice],\n",
    "        current_sequence[:, response_indices_slice]\n",
    "    )\n",
    "    num_tokens_to_be_masked_in_next_step = int(\n",
    "        initial_response_len * next_t_val)\n",
    "    num_tokens_to_be_masked_in_next_step = max(\n",
    "        0, num_tokens_to_be_masked_in_next_step)\n",
    "    next_sequence_step = r0_candidate.clone()\n",
    "    response_logits = logits[:, response_indices_slice, :].squeeze(0)\n",
    "    response_probs = F.softmax(response_logits, dim=-1)\n",
    "    predicted_tokens_response = predicted_tokens_all[:, response_indices_slice].squeeze(0)\n",
    "    # low confidence remasking strategy\n",
    "    predicted_confidence = response_probs.gather(1, predicted_tokens_response.unsqueeze(-1)).squeeze(-1)\n",
    "    sorted_confidences, sorted_indices_in_response = torch.sort(predicted_confidence, descending=False)\n",
    "    relative_indices_to_remask = sorted_indices_in_response[:num_tokens_to_be_masked_in_next_step]\n",
    "    full_indices_to_remask = response_indices_slice.start + relative_indices_to_remask\n",
    "    next_sequence_step[:, full_indices_to_remask] = mask_token_id\n",
    "    current_sequence = next_sequence_step\n",
    "    \n",
    "    if (current_sequence[:, response_indices_slice] != mask_token_id).all():\n",
    "        break\n",
    "\n",
    "\n",
    "tokenizer.decode_batch(current_sequence.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647203fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aptorch-DwoBsKDE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
